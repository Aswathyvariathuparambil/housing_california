{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T12:19:25.871123Z",
     "start_time": "2025-09-04T12:19:22.374882Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswat\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\aswat\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_23268\\726638690.py:29: RuntimeWarning: overflow encountered in square\n",
      "  loss = (1/(2*m)) * np.sum(error**2)  # 1/2 MSE\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_23268\\726638690.py:30: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  if abs(prev_loss - loss) < self.tol:\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_23268\\726638690.py:27: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.theta -= self.lr * gradient\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Experiment 1\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m exp1 \u001b[38;5;241m=\u001b[39m run_experiment(\u001b[38;5;28;01mlambda\u001b[39;00m df: df\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m    109\u001b[0m     MedianIncome2\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_income\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    110\u001b[0m     LogPopulation\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog1p(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopulation\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    111\u001b[0m     RoomsPerHousehold\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_rooms\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhouseholds\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n\u001b[0;32m    112\u001b[0m ), run_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssignment3_Exp1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Experiment 2\u001b[39;00m\n\u001b[0;32m    115\u001b[0m exp2 \u001b[38;5;241m=\u001b[39m run_experiment(\u001b[38;5;28;01mlambda\u001b[39;00m df: df\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m    116\u001b[0m     IncomeXRooms\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_income\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_rooms\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    117\u001b[0m     BedroomsRatio\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_bedrooms\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_rooms\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m),\n\u001b[0;32m    118\u001b[0m     PopPerHousehold\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopulation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhouseholds\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n\u001b[0;32m    119\u001b[0m ), run_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssignment3_Exp2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 94\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(features_fn, run_id)\u001b[0m\n\u001b[0;32m     91\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred[mask_pred]\n\u001b[0;32m     92\u001b[0m y_clean \u001b[38;5;241m=\u001b[39m y_new[mask_pred]\n\u001b[1;32m---> 94\u001b[0m mse_half \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_clean))) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum((y_pred \u001b[38;5;241m-\u001b[39m y_clean)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     95\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_clean, y_pred)\n\u001b[0;32m     97\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_id,\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning Rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39miters_to_converge\n\u001b[0;32m    104\u001b[0m })\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ----------------------\n",
    "# Gradient Descent Linear Regression\n",
    "# ----------------------\n",
    "class LinearRegressionGD:\n",
    "    def __init__(self, lr=0.01, n_iter=1000, tol=1e-6):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.theta = None\n",
    "        self.converged = False\n",
    "        self.iters_to_converge = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.theta = np.zeros(n)\n",
    "        prev_loss = float('inf')\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            y_pred = X.dot(self.theta)\n",
    "            error = y_pred - y\n",
    "            gradient = (1/m) * X.T.dot(error)\n",
    "            self.theta -= self.lr * gradient\n",
    "\n",
    "            loss = (1/(2*m)) * np.sum(error**2)  # 1/2 MSE\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                self.converged = True\n",
    "                self.iters_to_converge = i+1\n",
    "                break\n",
    "            prev_loss = loss\n",
    "\n",
    "        if not self.converged:\n",
    "            self.iters_to_converge = self.n_iter\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.theta)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Load and Clean Data\n",
    "# ----------------------\n",
    "file_path = \"california_housing.csv\"  # replace with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop empty rows\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Drop non-numeric / unwanted columns\n",
    "drop_cols = [\"ocean_proximity\", \"latitude\", \"longitude\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"median_house_value\", axis=1)\n",
    "y = df[\"median_house_value\"].values\n",
    "\n",
    "# ----------------------\n",
    "# Assignment 3: Non-linear Experiments\n",
    "# ----------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.drop(\"median_house_value\", axis=1))\n",
    "X = pd.DataFrame(X_scaled, columns=df.drop(\"median_house_value\", axis=1).columns)\n",
    "\n",
    "def run_experiment(features_fn, run_id):\n",
    "    X_new = features_fn(X.copy())\n",
    "    # Drop NaN or infinite values\n",
    "    X_new = X_new.replace([np.inf, -np.inf], np.nan)\n",
    "    mask = ~X_new.isna().any(axis=1)\n",
    "    X_new = X_new.loc[mask].reset_index(drop=True)\n",
    "    y_new = pd.Series(y).loc[mask].reset_index(drop=True).values\n",
    "\n",
    "    # Ensure y_new has the same length as X_new\n",
    "    if len(y_new) != len(X_new):\n",
    "        min_len = min(len(y_new), len(X_new))\n",
    "        X_new = X_new.iloc[:min_len]\n",
    "        y_new = y_new[:min_len]\n",
    "\n",
    "    X_mat = np.c_[np.ones(len(X_new)), X_new.values]\n",
    "\n",
    "    results = []\n",
    "    for lr in [0.001, 0.01, 0.1]:\n",
    "        model = LinearRegressionGD(lr=lr, n_iter=5000)\n",
    "        model.fit(X_mat, y_new)\n",
    "        y_pred = model.predict(X_mat)\n",
    "\n",
    "        # Drop any residual NaN values in predictions\n",
    "        mask_pred = ~np.isnan(y_pred)\n",
    "        y_pred = y_pred[mask_pred]\n",
    "        y_clean = y_new[mask_pred]\n",
    "\n",
    "        mse_half = (1/(2*len(y_clean))) * np.sum((y_pred - y_clean)**2)\n",
    "        r2 = r2_score(y_clean, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"Run\": run_id,\n",
    "            \"Learning Rate\": lr,\n",
    "            \"1/2 MSE\": round(mse_half, 4),\n",
    "            \"R2\": round(r2, 4),\n",
    "            \"Converged\": model.converged,\n",
    "            \"Iterations\": model.iters_to_converge\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Experiment 1\n",
    "exp1 = run_experiment(lambda df: df.assign(\n",
    "    MedianIncome2=df[\"median_income\"]**2,\n",
    "    LogPopulation=np.log1p(df[\"population\"]),\n",
    "    RoomsPerHousehold=df[\"total_rooms\"] / (df[\"households\"] + 1e-6)\n",
    "), run_id=\"Assignment3_Exp1\")\n",
    "\n",
    "# Experiment 2\n",
    "exp2 = run_experiment(lambda df: df.assign(\n",
    "    IncomeXRooms=df[\"median_income\"] * df[\"total_rooms\"],\n",
    "    BedroomsRatio=df[\"total_bedrooms\"] / (df[\"total_rooms\"] + 1e-6),\n",
    "    PopPerHousehold=df[\"population\"] / (df[\"households\"] + 1e-6)\n",
    "), run_id=\"Assignment3_Exp2\")\n",
    "\n",
    "# Experiment 3\n",
    "exp3 = run_experiment(lambda df: df.assign(\n",
    "    Age2=df[\"housing_median_age\"]**2,\n",
    "    LogRooms=np.log1p(df[\"total_rooms\"]),\n",
    "    Income2=df[\"median_income\"]**2\n",
    "), run_id=\"Assignment3_Exp3\")\n",
    "\n",
    "assignment3_results = pd.concat([exp1, exp2, exp3], ignore_index=True)\n",
    "print(\"Assignment 3 Results:\\n\", assignment3_results)\n",
    "assignment3_results.to_excel(\"assignment3_results.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d69777f47df68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
