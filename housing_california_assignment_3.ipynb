{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T14:20:23.406014Z",
     "start_time": "2025-09-11T14:20:17.673206Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ----------------------\n",
    "# Gradient Descent Linear Regression\n",
    "# ----------------------\n",
    "class LinearRegressionGD:\n",
    "    def __init__(self, lr=0.01, n_iter=1000, tol=1e-6):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.theta = None\n",
    "        self.converged = False\n",
    "        self.iters_to_converge = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.theta = np.zeros(n)\n",
    "        prev_loss = float('inf')\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            y_pred = X.dot(self.theta)\n",
    "            error = y_pred - y\n",
    "            gradient = (1/m) * X.T.dot(error)\n",
    "            self.theta -= self.lr * gradient\n",
    "\n",
    "            loss = (1/(2*m)) * np.sum(error**2)  # 1/2 MSE\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                self.converged = True\n",
    "                self.iters_to_converge = i+1\n",
    "                break\n",
    "            prev_loss = loss\n",
    "\n",
    "        if not self.converged:\n",
    "            self.iters_to_converge = self.n_iter\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.theta)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Load and Clean Data\n",
    "# ----------------------\n",
    "file_path = \"california_housing.csv\"  # replace with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop empty rows\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Drop non-numeric / unwanted columns\n",
    "drop_cols = [\"ocean_proximity\", \"latitude\", \"longitude\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"median_house_value\", axis=1)\n",
    "y = df[\"median_house_value\"].values\n",
    "\n",
    "# ----------------------\n",
    "# Assignment 3: Non-linear Experiments\n",
    "# ----------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.drop(\"median_house_value\", axis=1))\n",
    "X = pd.DataFrame(X_scaled, columns=df.drop(\"median_house_value\", axis=1).columns)\n",
    "\n",
    "def safe_divide(numerator, denominator, feature_name=\"\"):\n",
    "    zeros = (denominator == 0).sum()\n",
    "    if zeros > 0:\n",
    "        print(f\"[INFO] {zeros} zero values found in denominator for {feature_name}. Replaced with 0.\")\n",
    "    return np.where(denominator != 0, numerator / denominator, 0)\n",
    "\n",
    "def run_experiment(features_fn, run_id):\n",
    "    X_new = features_fn(X.copy())\n",
    "    # Drop NaN or infinite values\n",
    "    X_new = X_new.replace([np.inf, -np.inf], np.nan)\n",
    "    mask = ~X_new.isna().any(axis=1)\n",
    "    X_new = X_new.loc[mask].reset_index(drop=True)\n",
    "    y_new = pd.Series(y).loc[mask].reset_index(drop=True).values\n",
    "     \n",
    "\n",
    "    # Ensure y_new has the same length as X_new\n",
    "    if len(y_new) != len(X_new):\n",
    "        min_len = min(len(y_new), len(X_new))\n",
    "        X_new = X_new.iloc[:min_len]\n",
    "        y_new = y_new[:min_len]\n",
    "\n",
    "    X_mat = np.c_[np.ones(len(X_new)), X_new.values]\n",
    "\n",
    "    results = []\n",
    "    for lr in [0.001, 0.01, 0.1]:\n",
    "        model = LinearRegressionGD(lr=lr, n_iter=5000)\n",
    "        model.fit(X_mat, y_new)\n",
    "        y_pred = model.predict(X_mat)\n",
    "\n",
    "        # Drop any residual NaN values in predictions\n",
    "        mask_pred = ~np.isnan(y_pred)\n",
    "        y_pred = y_pred[mask_pred]\n",
    "        y_clean = y_new[mask_pred]\n",
    "\n",
    "        mse_half = (1/(2*len(y_clean))) * np.sum((y_pred - y_clean)**2)\n",
    "        r2 = r2_score(y_clean, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"Run\": run_id,\n",
    "            \"Learning Rate\": lr,\n",
    "            \"1/2 MSE\": round(mse_half, 4),\n",
    "            \"R2\": round(r2, 4),\n",
    "            \"Converged\": model.converged,\n",
    "            \"Iterations\": model.iters_to_converge\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Experiment 1\n",
    "exp1 = run_experiment(lambda df: df.assign(\n",
    "    MedianIncome2=df[\"median_income\"]**2,\n",
    "    LogPopulation=np.log1p(df[\"population\"]),\n",
    "    RoomsPerHousehold=safe_divide(df[\"total_rooms\"], df[\"households\"])\n",
    "), run_id=\"Assignment3_Exp1\")\n",
    "\n",
    "# Experiment 2\n",
    "exp2 = run_experiment(lambda df: df.assign(\n",
    "    IncomeXRooms=df[\"median_income\"] * df[\"total_rooms\"],\n",
    "    BedroomsRatio=safe_divide(df[\"total_bedrooms\"], df[\"total_rooms\"]),\n",
    "    PopPerHousehold=safe_divide(df[\"population\"], df[\"households\"])\n",
    "), run_id=\"Assignment3_Exp2\")\n",
    "\n",
    "# Experiment 3\n",
    "exp3 = run_experiment(lambda df: df.assign(\n",
    "    Age2=df[\"housing_median_age\"]**2,\n",
    "    LogRooms=np.log1p(df[\"total_rooms\"]),\n",
    "    Income2=df[\"median_income\"]**2\n",
    "), run_id=\"Assignment3_Exp3\")\n",
    "\n",
    "assignment3_results = pd.concat([exp1, exp2, exp3], ignore_index=True)\n",
    "print(\"Assignment 3 Results:\\n\", assignment3_results)\n",
    "assignment3_results.to_excel(\"assignment3_results.xlsx\", index=False)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswat\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\aswat\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_21628\\1489392090.py:29: RuntimeWarning: overflow encountered in square\n",
      "  loss = (1/(2*m)) * np.sum(error**2)  # 1/2 MSE\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_21628\\1489392090.py:30: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  if abs(prev_loss - loss) < self.tol:\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_21628\\1489392090.py:27: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.theta -= self.lr * gradient\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 115\u001B[0m\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mDataFrame(results)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;66;03m# Experiment 1\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m exp1 \u001B[38;5;241m=\u001B[39m run_experiment(\u001B[38;5;28;01mlambda\u001B[39;00m df: df\u001B[38;5;241m.\u001B[39massign(\n\u001B[0;32m    116\u001B[0m     MedianIncome2\u001B[38;5;241m=\u001B[39mdf[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian_income\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m    117\u001B[0m     LogPopulation\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mlog1p(df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpopulation\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[0;32m    118\u001B[0m     RoomsPerHousehold\u001B[38;5;241m=\u001B[39msafe_divide(df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_rooms\u001B[39m\u001B[38;5;124m\"\u001B[39m], df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhouseholds\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    119\u001B[0m ), run_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAssignment3_Exp1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    121\u001B[0m \u001B[38;5;66;03m# Experiment 2\u001B[39;00m\n\u001B[0;32m    122\u001B[0m exp2 \u001B[38;5;241m=\u001B[39m run_experiment(\u001B[38;5;28;01mlambda\u001B[39;00m df: df\u001B[38;5;241m.\u001B[39massign(\n\u001B[0;32m    123\u001B[0m     IncomeXRooms\u001B[38;5;241m=\u001B[39mdf[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian_income\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m*\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_rooms\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    124\u001B[0m     BedroomsRatio\u001B[38;5;241m=\u001B[39msafe_divide(df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_bedrooms\u001B[39m\u001B[38;5;124m\"\u001B[39m], df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal_rooms\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[0;32m    125\u001B[0m     PopPerHousehold\u001B[38;5;241m=\u001B[39msafe_divide(df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpopulation\u001B[39m\u001B[38;5;124m\"\u001B[39m], df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhouseholds\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    126\u001B[0m ), run_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAssignment3_Exp2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[1], line 101\u001B[0m, in \u001B[0;36mrun_experiment\u001B[1;34m(features_fn, run_id)\u001B[0m\n\u001B[0;32m     98\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m y_pred[mask_pred]\n\u001B[0;32m     99\u001B[0m y_clean \u001B[38;5;241m=\u001B[39m y_new[mask_pred]\n\u001B[1;32m--> 101\u001B[0m mse_half \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m(\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(y_clean))) \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msum((y_pred \u001B[38;5;241m-\u001B[39m y_clean)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    102\u001B[0m r2 \u001B[38;5;241m=\u001B[39m r2_score(y_clean, y_pred)\n\u001B[0;32m    104\u001B[0m results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_id,\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLearning Rate\u001B[39m\u001B[38;5;124m\"\u001B[39m: lr,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIterations\u001B[39m\u001B[38;5;124m\"\u001B[39m: model\u001B[38;5;241m.\u001B[39miters_to_converge\n\u001B[0;32m    111\u001B[0m })\n",
      "\u001B[1;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc114eb-2e03-4208-9ad6-d04eeae9be12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T14:20:23.428417500Z",
     "start_time": "2025-09-04T12:19:22.374882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 12996 non-positive values in population, replaced with 0 before log1p.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswat\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\aswat\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_3276\\2987980211.py:29: RuntimeWarning: overflow encountered in square\n",
      "  loss = (1/(2*m)) * np.sum(error**2)  # 1/2 MSE\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_3276\\2987980211.py:30: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  if abs(prev_loss - loss) < self.tol:\n",
      "C:\\Users\\aswat\\AppData\\Local\\Temp\\ipykernel_3276\\2987980211.py:27: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.theta -= self.lr * gradient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No valid predictions in Assignment3_Exp2 (lr=0.01), skipping.\n",
      "[INFO] 13184 non-positive values in total_rooms, replaced with 0 before log1p.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswat\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 3 Results:\n",
      "                 Run  Learning Rate       1/2 MSE      R2  Converged  \\\n",
      "0  Assignment3_Exp1         0.0001  1.133936e+10 -0.7020      False   \n",
      "1  Assignment3_Exp1         0.0010  3.086477e+09  0.5367      False   \n",
      "2  Assignment3_Exp1         0.0100  2.827124e+09  0.5757      False   \n",
      "3  Assignment3_Exp2         0.0001  1.220093e+10 -0.8313      False   \n",
      "4  Assignment3_Exp2         0.0010  3.023054e+09  0.5462      False   \n",
      "5  Assignment3_Exp3         0.0001  9.263571e+09 -0.3904      False   \n",
      "6  Assignment3_Exp3         0.0010  3.232117e+09  0.5149      False   \n",
      "7  Assignment3_Exp3         0.0100  2.821334e+09  0.5765      False   \n",
      "\n",
      "   Iterations  \n",
      "0        5000  \n",
      "1        5000  \n",
      "2        5000  \n",
      "3        5000  \n",
      "4        5000  \n",
      "5        5000  \n",
      "6        5000  \n",
      "7        5000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ----------------------\n",
    "# Gradient Descent Linear Regression\n",
    "# ----------------------\n",
    "class LinearRegressionGD:\n",
    "    def __init__(self, lr=0.01, n_iter=1000, tol=1e-6):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.theta = None\n",
    "        self.converged = False\n",
    "        self.iters_to_converge = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.theta = np.zeros(n)\n",
    "        prev_loss = float('inf')\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            y_pred = X.dot(self.theta)\n",
    "            error = y_pred - y\n",
    "            gradient = (1/m) * X.T.dot(error)\n",
    "            self.theta -= self.lr * gradient\n",
    "\n",
    "            loss = (1/(2*m)) * np.sum(error**2)  # 1/2 MSE\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                self.converged = True\n",
    "                self.iters_to_converge = i+1\n",
    "                break\n",
    "            prev_loss = loss\n",
    "\n",
    "        if not self.converged:\n",
    "            self.iters_to_converge = self.n_iter\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.theta)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Load and Clean Data\n",
    "# ----------------------\n",
    "file_path = \"california_housing.csv\"  # replace with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop empty rows\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Drop non-numeric / unwanted columns\n",
    "drop_cols = [\"ocean_proximity\", \"latitude\", \"longitude\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"median_house_value\", axis=1)\n",
    "y = df[\"median_house_value\"].values\n",
    "\n",
    "# ----------------------\n",
    "# Assignment 3: Non-linear Experiments\n",
    "# ----------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.drop(\"median_house_value\", axis=1))\n",
    "X = pd.DataFrame(X_scaled, columns=df.drop(\"median_house_value\", axis=1).columns)\n",
    "\n",
    "def safe_divide(numerator, denominator, feature_name=\"\"):\n",
    "    zeros = (denominator == 0).sum()\n",
    "    if zeros > 0:\n",
    "        print(f\"[INFO] {zeros} zeros in denominator for {feature_name}, replaced with 0.\")\n",
    "    return np.where(denominator != 0, numerator / denominator, 0)\n",
    "\n",
    "def safe_log1p(series, feature_name=\"\"):\n",
    "    bad = (series <= 0).sum()\n",
    "    if bad > 0:\n",
    "        print(f\"[INFO] {bad} non-positive values in {feature_name}, replaced with 0 before log1p.\")\n",
    "    return np.where(series > 0, np.log1p(series), 0)\n",
    "\n",
    "def run_experiment(features_fn, run_id):\n",
    "    X_new = features_fn(X.copy())\n",
    "    # Drop NaN or infinite values\n",
    "    X_new = X_new.replace([np.inf, -np.inf], np.nan)\n",
    "    mask = ~X_new.isna().any(axis=1)\n",
    "    dropped = len(mask) - mask.sum()\n",
    "    if dropped > 0:\n",
    "        print(f\"[INFO] Dropped {dropped} rows with NaN/Inf in {run_id}\")\n",
    "    X_new = X_new.loc[mask].reset_index(drop=True)\n",
    "    y_new = pd.Series(y).loc[mask].reset_index(drop=True).values\n",
    "\n",
    "    if len(y_new) == 0:\n",
    "        print(f\"[WARNING] No valid rows left in {run_id}, skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    X_mat = np.c_[np.ones(len(X_new)), X_new.values]\n",
    "\n",
    "    results = []\n",
    "    for lr in [0.0001, 0.001, 0.01]:  # safer learning rates\n",
    "        model = LinearRegressionGD(lr=lr, n_iter=5000)\n",
    "        model.fit(X_mat, y_new)\n",
    "        y_pred = model.predict(X_mat)\n",
    "\n",
    "        mask_pred = ~np.isnan(y_pred)\n",
    "        y_pred = y_pred[mask_pred]\n",
    "        y_clean = y_new[mask_pred]\n",
    "\n",
    "        if len(y_clean) == 0:\n",
    "            print(f\"[WARNING] No valid predictions in {run_id} (lr={lr}), skipping.\")\n",
    "            continue\n",
    "\n",
    "        mse_half = (1/(2*len(y_clean))) * np.sum((y_pred - y_clean)**2)\n",
    "        r2 = r2_score(y_clean, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"Run\": run_id,\n",
    "            \"Learning Rate\": lr,\n",
    "            \"1/2 MSE\": round(mse_half, 4),\n",
    "            \"R2\": round(r2, 4),\n",
    "            \"Converged\": model.converged,\n",
    "            \"Iterations\": model.iters_to_converge\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Experiments\n",
    "# ----------------------\n",
    "exp1 = run_experiment(lambda df: df.assign(\n",
    "    MedianIncome2=df[\"median_income\"]**2,\n",
    "    LogPopulation=safe_log1p(df[\"population\"], \"population\"),\n",
    "    RoomsPerHousehold=safe_divide(df[\"total_rooms\"], df[\"households\"], \"RoomsPerHousehold\")\n",
    "), run_id=\"Assignment3_Exp1\")\n",
    "\n",
    "exp2 = run_experiment(lambda df: df.assign(\n",
    "    IncomeXRooms=df[\"median_income\"] * df[\"total_rooms\"],\n",
    "    BedroomsRatio=safe_divide(df[\"total_bedrooms\"], df[\"total_rooms\"], \"BedroomsRatio\"),\n",
    "    PopPerHousehold=safe_divide(df[\"population\"], df[\"households\"], \"PopPerHousehold\")\n",
    "), run_id=\"Assignment3_Exp2\")\n",
    "\n",
    "exp3 = run_experiment(lambda df: df.assign(\n",
    "    Age2=df[\"housing_median_age\"]**2,\n",
    "    LogRooms=safe_log1p(df[\"total_rooms\"], \"total_rooms\"),\n",
    "    Income2=df[\"median_income\"]**2\n",
    "), run_id=\"Assignment3_Exp3\")\n",
    "\n",
    "assignment3_results = pd.concat([exp1, exp2, exp3], ignore_index=True)\n",
    "print(\"Assignment 3 Results:\\n\", assignment3_results)\n",
    "assignment3_results.to_excel(\"assignment3_results.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d69777f47df68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21628eb4-4861-4de9-9d84-73a39f63a0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
